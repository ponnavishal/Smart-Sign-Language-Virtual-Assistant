# Smart-Sign-Language-Virtual-Assistant
This project is a deep learning–based Smart Sign Language Detection System that recognizes American Sign Language (ASL) alphabet signs (A–Z) in real time using a webcam. The system is designed to help bridge the communication gap between hearing-impaired individuals and the general public by converting hand gestures into readable text.

DATASET
ASL Alphabet Recognition System using Deep Learning
This project uses a 29-class ASL alphabet dataset to train a high-accuracy CNN model capable of recognizing American Sign Language gestures in real time using a webcam. Includes dataset link, model training code, real-time prediction script, and deployment-ready app.py.

✅ Standard Description

American Sign Language (ASL) Alphabet Classification | Deep Learning | Real-Time Detection

This repository contains a complete implementation of an ASL hand-sign recognition system trained on a 29-class ASL Alphabet dataset. The model uses Convolutional Neural Networks (CNN) for image classification and integrates OpenCV for real-time webcam-based sign prediction.
The project includes preprocessing, model training, evaluation, saved model files, and a ready-to-run real-time detection app.py.

Features

29 ASL gesture classes (A–Z + “Space”, “Delete”, “Nothing”)

Clean and simple CNN model for fast training

Real-time prediction using webcam

High accuracy & optimized model

Dataset loading + preprocessing

Saved model (.h5) with code for future expansion
